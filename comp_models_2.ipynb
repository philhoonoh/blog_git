{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef4c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:140% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:140% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb972cf",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/philhoonoh/blog_git/blob/main/comp_models_2.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View Source</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1040efc7",
   "metadata": {},
   "source": [
    "# PyTorch Model - timm library, torchvision.models part2)\n",
    "  \n",
    "> Application of timm and torchvision.model libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc909392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7cf207",
   "metadata": {},
   "source": [
    "## Timm Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd49121",
   "metadata": {},
   "source": [
    "### Creating Custom Model using convnext_small\n",
    "\n",
    "> Implementing Custom Model for ThreeWayStratifiedDataset described in [https://psyduck5.tistory.com/10]  \n",
    "> Attempt1. Sharing pretrained embeddings but constructing differnet layers for each labels (age, mask, gender)  \n",
    "> Attempt2. For Generalization, applying dropout layers  \n",
    "> Goal. Not Enough GPU resources to train each labels. Therefore, by implementing Attempt1, Attemp2, trying the acheive the ensemble-like effects  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c3d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNextLSmallCustom(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('convnext_small', pretrained=True, num_classes = 1536)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "                    nn.Dropout(0.5) for _ in range(5)])\n",
    "        self.age_layer = nn.Linear(in_features=1536, out_features=3, bias=True)\n",
    "        self.mask_layer = nn.Linear(in_features=1536, out_features=2, bias=True)\n",
    "        self.sex_layer = nn.Linear(in_features=1536, out_features=2, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x_ = self.dropout(x)\n",
    "        \n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i==0:\n",
    "                x_age = self.age_layer(dropout(x_))\n",
    "                x_mask = self.mask_layer(dropout(x_))\n",
    "                x_sex = self.sex_layer(dropout(x_))\n",
    "            else:\n",
    "                x_age += self.age_layer(dropout(x_))\n",
    "                x_mask += self.mask_layer(dropout(x_))\n",
    "                x_sex += self.sex_layer(dropout(x_))\n",
    "        else:\n",
    "            x_age /= len(self.dropouts)\n",
    "            x_mask /= len(self.dropouts)\n",
    "            x_sex /= len(self.dropouts)\n",
    "        \n",
    "        return x_age, x_mask, x_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c1e320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0389, 0.0142, 0.0060]], grad_fn=<DivBackward0>), tensor([[ 0.0206, -0.0145]], grad_fn=<DivBackward0>), tensor([[-0.0092, -0.0465]], grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "model = ConvNextLSmallCustom()\n",
    "model.eval()\n",
    "result = model(torch.randn(1,3,224,224))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ba258",
   "metadata": {},
   "source": [
    "## Torchvision models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc54aaff",
   "metadata": {},
   "source": [
    "### Initialzing with functions \n",
    "\n",
    "> Implementing user-defined functions for changing the last layer and initializing weights  \n",
    "> Attempt1. Define a function to automatically finds out the last layer of the model and change the out_features  \n",
    "> Attempt2. Define a function to initialzing wegihts to the modified layers.  \n",
    "> Goal. With these functions, aimimg to contruct the custom model class just like timm library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df2aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_uniform_(m.weight.data, nonlinearity='relu') \n",
    "    \n",
    "def change_last_layer(model, num_classes):\n",
    "    name_last_layer = list(model.named_modules())[-1][0]\n",
    "    \n",
    "    if name_last_layer == 'classifier':\n",
    "        model.classifier = nn.Linear(in_features = model.classifier.in_features,\n",
    "                                              out_features = num_classes, bias = True)\n",
    "        initialize_weights(model.classifier)\n",
    "        return model\n",
    "    \n",
    "    elif name_last_layer == 'fc':\n",
    "        model.fc = nn.Linear(in_features = model.fc.in_features,\n",
    "                                      out_features = num_classes, bias = True)\n",
    "        initialize_weights(model.fc)\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        raise Exceptionception('last layer should be nn.Linear Module named as either fc or classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb9066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet161(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNet161, self).__init__()\n",
    "        self.model = models.densenet161(pretrained = True)\n",
    "        self.model = change_last_layer(self.model, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28c3c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2204,  0.6942, -0.8310,  0.0541, -1.7376, -0.1588,  0.0203,  0.7483,\n",
       "          1.5705, -0.7220]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNet161(10)\n",
    "model.eval()\n",
    "model(torch.randn(1,3,224,224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_transformers",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
