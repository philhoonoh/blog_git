{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "856a49d1",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/philhoonoh/blog_git/blob/main/voila.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View Source</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-sensitivity",
   "metadata": {},
   "source": [
    "## 0. Libarary Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "novel-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image as display_image\n",
    "\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-recall",
   "metadata": {},
   "source": [
    "## 1. 모델 정의 & 설정\n",
    "### 사전에 학습된 모델을 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passive-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frequent-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEfficientNet(nn.Module) :\n",
    "    '''\n",
    "    EfiicientNet-b4의 출력층만 변경합니다.\n",
    "    한번에 18개의 Class를 예측하는 형태의 Model입니다.\n",
    "    '''\n",
    "    def __init__(self, num_classes: int = 18) :\n",
    "        super(MyEfficientNet, self).__init__()\n",
    "        self.EFF = EfficientNet.from_pretrained('efficientnet-b4', in_channels=3, num_classes=num_classes)\n",
    "    \n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.EFF(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "usual-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image_bytes) -> torch.Tensor:\n",
    "    transform = albumentations.Compose([\n",
    "            albumentations.Resize(height=512, width=384),\n",
    "            albumentations.Normalize(mean=(0.5, 0.5, 0.5), \n",
    "                                     std=(0.2, 0.2, 0.2)),\n",
    "            albumentations.pytorch.transforms.ToTensorV2()\n",
    "        ])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.convert('RGB')\n",
    "    image_array = np.array(image)\n",
    "    return transform(image=image_array)['image'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "demanding-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MyEfficientNet(num_classes=18).to(device)\n",
    "model.load_state_dict(torch.load(config['model_path'], map_location=device))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "technical-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(image_bytes: bytes) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tensor = transform_image(image_bytes=image_bytes).to(device)\n",
    "    outputs = model.forward(tensor)\n",
    "    _, y_hat = outputs.max(1)\n",
    "    return tensor, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-malaysia",
   "metadata": {},
   "source": [
    "## 2. Inference \n",
    "- TODO : 파일 업로더 생성\n",
    "- TODO : 버튼 클릭시 이미지 보이기\n",
    "- TODO : 인퍼런스 버튼 클릭시 인퍼런스 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f01c677-3619-4a75-837e-8232be36e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader = widgets.FileUpload(\n",
    "    accept ='.png, .jpg, .jpeg',\n",
    "    multiple=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7c15f4-f103-4179-9b03-737eed036bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ed55683de245c78bf0191a67e3a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.png, .jpg, .jpeg', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13728bc4-ab4d-4ff5-a1a1-8a6cc4ddda49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb32bdacaaf248a1906b83009a1aa997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Display Image', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7377d5befd414b3aa8e0573874dcd3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def on_display_click_callback(clicked_button: widgets.Button) -> None:\n",
    "    global content\n",
    "    uploaded_filename = next(iter(uploader.value))\n",
    "    content = uploader.value[uploaded_filename]['content']\n",
    "    display_image_space.value = content \n",
    "\n",
    "\n",
    "display_button = widgets.Button(description = \"Display Image\")\n",
    "display_image_space = widgets.Image()\n",
    "\n",
    "display_button.on_click(on_display_click_callback)\n",
    "display(display_button, display_image_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb0c91c4-8a15-4f3b-a414-a690b7eb5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_inference_click_callback(clicked_button: widgets.Button) -> None:\n",
    "    with inference_output:\n",
    "        inference_output.clear_output()\n",
    "        _, output = get_prediction(content)\n",
    "        print(config['classes'][output.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4da4cf5e-ade2-441c-b6b8-3499e84dc59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c611109ac64176898ed0ba736fbc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Inference!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8dd1921446b40328eb89b96e31fe647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid baclk'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_button = widgets.Button(description=\"Inference!\")\n",
    "inference_output = widgets.Output(layout = {'border' : '1px solid baclk'})\n",
    "\n",
    "inference_button.on_click(on_inference_click_callback)\n",
    "display(inference_button, inference_output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eda028c0af24c538d588c0b6932d10f4eb16a72f48d35998721da8db38e4b827"
  },
  "kernelspec": {
   "display_name": "voila",
   "language": "python",
   "name": "voila"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
